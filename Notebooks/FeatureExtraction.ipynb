{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e63c365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57be24e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the data\n",
    "df = pd.read_csv(\"/home/amon/Downloads/data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e8946bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the column with missing values\n",
    "df_na_val = df.drop(['Unnamed: 32'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f94e267a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
       "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
       "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
       "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
       "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
       "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
       "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
       "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "count     569.000000  ...    569.000000     569.000000       569.000000   \n",
       "mean        0.181162  ...     16.269190      25.677223       107.261213   \n",
       "std         0.027414  ...      4.833242       6.146258        33.602542   \n",
       "min         0.106000  ...      7.930000      12.020000        50.410000   \n",
       "25%         0.161900  ...     13.010000      21.080000        84.110000   \n",
       "50%         0.179200  ...     14.970000      25.410000        97.660000   \n",
       "75%         0.195700  ...     18.790000      29.720000       125.400000   \n",
       "max         0.304000  ...     36.040000      49.540000       251.200000   \n",
       "\n",
       "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count   569.000000        569.000000         569.000000       569.000000   \n",
       "mean    880.583128          0.132369           0.254265         0.272188   \n",
       "std     569.356993          0.022832           0.157336         0.208624   \n",
       "min     185.200000          0.071170           0.027290         0.000000   \n",
       "25%     515.300000          0.116600           0.147200         0.114500   \n",
       "50%     686.500000          0.131300           0.211900         0.226700   \n",
       "75%    1084.000000          0.146000           0.339100         0.382900   \n",
       "max    4254.000000          0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "count            569.000000      569.000000               569.000000  \n",
       "mean               0.114606        0.290076                 0.083946  \n",
       "std                0.065732        0.061867                 0.018061  \n",
       "min                0.000000        0.156500                 0.055040  \n",
       "25%                0.064930        0.250400                 0.071460  \n",
       "50%                0.099930        0.282200                 0.080040  \n",
       "75%                0.161400        0.317900                 0.092080  \n",
       "max                0.291000        0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_na_val.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "756928c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_na_val['diagnosis'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9113638",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_na_val['diagnosis'].replace('B',0,inplace=True)\n",
    "df_na_val['diagnosis'].replace('M',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8b8eaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302          1        17.99         10.38          122.80     1001.0   \n",
       "1    842517          1        20.57         17.77          132.90     1326.0   \n",
       "2  84300903          1        19.69         21.25          130.00     1203.0   \n",
       "3  84348301          1        11.42         20.38           77.58      386.1   \n",
       "4  84358402          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_na_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "250fa267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23640517 1.29767572 1.09706398 ... 2.29607613 2.75062224 1.93701461]\n",
      " [0.23640344 1.29767572 1.82982061 ... 1.0870843  0.24388967 0.28118999]\n",
      " [0.43174109 1.29767572 1.57988811 ... 1.95500035 1.152255   0.20139121]\n",
      " ...\n",
      " [0.23572747 1.29767572 0.70228425 ... 0.41406869 1.10454895 0.31840916]\n",
      " [0.23572517 1.29767572 1.83834103 ... 2.28998549 1.91908301 2.21963528]\n",
      " [0.24240586 0.77060855 1.80840125 ... 1.74506282 0.04813821 0.75120669]]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "z = np.abs(stats.zscore(df_na_val))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92948f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_na_val[(z < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f620fa56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(487, 32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "770f3237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.2</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.1578</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.07613</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.4</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.1127</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.2</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "5        12.45         15.70           82.57      477.1          0.12780   \n",
       "6        18.25         19.98          119.60     1040.0          0.09463   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "5           0.17000          0.1578              0.08089         0.2087   \n",
       "6           0.10900          0.1127              0.07400         0.1794   \n",
       "\n",
       "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "1                 0.05667  ...         24.99          23.41            158.8   \n",
       "2                 0.05999  ...         23.57          25.53            152.5   \n",
       "4                 0.05883  ...         22.54          16.67            152.2   \n",
       "5                 0.07613  ...         15.47          23.75            103.4   \n",
       "6                 0.05742  ...         22.88          27.66            153.2   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "5       741.6            0.1791             0.5249           0.5355   \n",
       "6      1606.0            0.1442             0.2576           0.3784   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "5                0.1741          0.3985                  0.12440  \n",
       "6                0.1932          0.3063                  0.08368  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y includes our labels and x includes our features\n",
    "y = df_clean['diagnosis']                   # M or B \n",
    "list = ['id','diagnosis']\n",
    "x = df_clean.drop(list,axis = 1 )\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e34105a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83424397, 0.38362684, 0.82273105, ..., 0.68863384, 0.3717064 ,\n",
       "        0.42980015],\n",
       "       [0.78021978, 0.54926226, 0.79595605, ..., 0.89966679, 0.64240903,\n",
       "        0.41158614],\n",
       "       [0.81705445, 0.22037125, 0.84304312, ..., 0.60162903, 0.25062735,\n",
       "        0.27498103],\n",
       "       ...,\n",
       "       [0.89502118, 0.60352213, 0.90674915, ..., 0.82043688, 0.15526976,\n",
       "        0.20376929],\n",
       "       [0.80723187, 0.88243693, 0.80703536, ..., 0.60273973, 0.31587202,\n",
       "        0.14330888],\n",
       "       [0.59052121, 0.87434555, 0.59560521, ..., 0.52499074, 0.20483061,\n",
       "        0.29294207]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# define min max scaler\n",
    "scaler = MinMaxScaler()\n",
    "# transform data\n",
    "scaled = scaler.fit_transform(x)\n",
    "scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64f086da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.224859</td>\n",
       "      <td>-0.275471</td>\n",
       "      <td>2.086170</td>\n",
       "      <td>2.480931</td>\n",
       "      <td>-0.811123</td>\n",
       "      <td>-0.397576</td>\n",
       "      <td>0.205810</td>\n",
       "      <td>0.830214</td>\n",
       "      <td>0.151425</td>\n",
       "      <td>-0.936730</td>\n",
       "      <td>...</td>\n",
       "      <td>2.235281</td>\n",
       "      <td>-0.302860</td>\n",
       "      <td>1.956635</td>\n",
       "      <td>2.536527</td>\n",
       "      <td>-0.334504</td>\n",
       "      <td>-0.360396</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>1.371178</td>\n",
       "      <td>-0.181647</td>\n",
       "      <td>0.513669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.933363</td>\n",
       "      <td>0.600615</td>\n",
       "      <td>1.945675</td>\n",
       "      <td>2.048186</td>\n",
       "      <td>1.130272</td>\n",
       "      <td>1.580205</td>\n",
       "      <td>1.997254</td>\n",
       "      <td>2.611405</td>\n",
       "      <td>1.268360</td>\n",
       "      <td>-0.334883</td>\n",
       "      <td>...</td>\n",
       "      <td>1.889113</td>\n",
       "      <td>0.070575</td>\n",
       "      <td>1.732509</td>\n",
       "      <td>1.986246</td>\n",
       "      <td>0.641926</td>\n",
       "      <td>1.529480</td>\n",
       "      <td>1.220261</td>\n",
       "      <td>2.354829</td>\n",
       "      <td>1.554049</td>\n",
       "      <td>0.413568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.132110</td>\n",
       "      <td>-1.138970</td>\n",
       "      <td>2.192752</td>\n",
       "      <td>2.378902</td>\n",
       "      <td>0.404006</td>\n",
       "      <td>0.920621</td>\n",
       "      <td>2.006981</td>\n",
       "      <td>1.883255</td>\n",
       "      <td>0.138387</td>\n",
       "      <td>-0.545167</td>\n",
       "      <td>...</td>\n",
       "      <td>1.638020</td>\n",
       "      <td>-1.490104</td>\n",
       "      <td>1.721836</td>\n",
       "      <td>1.687713</td>\n",
       "      <td>0.310129</td>\n",
       "      <td>-0.214227</td>\n",
       "      <td>0.925945</td>\n",
       "      <td>0.965637</td>\n",
       "      <td>-0.957984</td>\n",
       "      <td>-0.337183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.464861</td>\n",
       "      <td>-0.796591</td>\n",
       "      <td>-0.352138</td>\n",
       "      <td>-0.505711</td>\n",
       "      <td>2.551567</td>\n",
       "      <td>1.826029</td>\n",
       "      <td>1.355252</td>\n",
       "      <td>1.160967</td>\n",
       "      <td>1.346589</td>\n",
       "      <td>2.590964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085505</td>\n",
       "      <td>-0.242970</td>\n",
       "      <td>-0.014255</td>\n",
       "      <td>-0.168983</td>\n",
       "      <td>2.286689</td>\n",
       "      <td>2.327057</td>\n",
       "      <td>1.717211</td>\n",
       "      <td>1.165819</td>\n",
       "      <td>2.302228</td>\n",
       "      <td>2.973075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.456368</td>\n",
       "      <td>0.280894</td>\n",
       "      <td>1.441833</td>\n",
       "      <td>1.474712</td>\n",
       "      <td>-0.038782</td>\n",
       "      <td>0.341354</td>\n",
       "      <td>0.624083</td>\n",
       "      <td>0.948384</td>\n",
       "      <td>0.073196</td>\n",
       "      <td>-0.800770</td>\n",
       "      <td>...</td>\n",
       "      <td>1.720905</td>\n",
       "      <td>0.445772</td>\n",
       "      <td>1.757412</td>\n",
       "      <td>1.756777</td>\n",
       "      <td>0.632446</td>\n",
       "      <td>0.203628</td>\n",
       "      <td>0.799810</td>\n",
       "      <td>1.495428</td>\n",
       "      <td>0.447869</td>\n",
       "      <td>0.142464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "1     2.224859     -0.275471        2.086170   2.480931        -0.811123   \n",
       "2     1.933363      0.600615        1.945675   2.048186         1.130272   \n",
       "4     2.132110     -1.138970        2.192752   2.378902         0.404006   \n",
       "5    -0.464861     -0.796591       -0.352138  -0.505711         2.551567   \n",
       "6     1.456368      0.280894        1.441833   1.474712        -0.038782   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "1         -0.397576        0.205810             0.830214       0.151425   \n",
       "2          1.580205        1.997254             2.611405       1.268360   \n",
       "4          0.920621        2.006981             1.883255       0.138387   \n",
       "5          1.826029        1.355252             1.160967       1.346589   \n",
       "6          0.341354        0.624083             0.948384       0.073196   \n",
       "\n",
       "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "1               -0.936730  ...      2.235281      -0.302860         1.956635   \n",
       "2               -0.334883  ...      1.889113       0.070575         1.732509   \n",
       "4               -0.545167  ...      1.638020      -1.490104         1.721836   \n",
       "5                2.590964  ...     -0.085505      -0.242970        -0.014255   \n",
       "6               -0.800770  ...      1.720905       0.445772         1.757412   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "1    2.536527         -0.334504          -0.360396         0.000953   \n",
       "2    1.986246          0.641926           1.529480         1.220261   \n",
       "4    1.687713          0.310129          -0.214227         0.925945   \n",
       "5   -0.168983          2.286689           2.327057         1.717211   \n",
       "6    1.756777          0.632446           0.203628         0.799810   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "1              1.371178       -0.181647                 0.513669  \n",
       "2              2.354829        1.554049                 0.413568  \n",
       "4              0.965637       -0.957984                -0.337183  \n",
       "5              1.165819        2.302228                 2.973075  \n",
       "6              1.495428        0.447869                 0.142464  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../scripts/\")\n",
    "from features import feature_scaling\n",
    "scaled_features = feature_scaling(x,'diagnosis')\n",
    "scaled_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "623b913c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.236405</td>\n",
       "      <td>1</td>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>...</td>\n",
       "      <td>1.886690</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.236403</td>\n",
       "      <td>1</td>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>...</td>\n",
       "      <td>1.805927</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.431741</td>\n",
       "      <td>1</td>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>...</td>\n",
       "      <td>1.511870</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.432121</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281464</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.432201</td>\n",
       "      <td>1</td>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298575</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0 -0.236405          1     1.097064     -2.073335        1.269934   0.984375   \n",
       "1 -0.236403          1     1.829821     -0.353632        1.685955   1.908708   \n",
       "2  0.431741          1     1.579888      0.456187        1.566503   1.558884   \n",
       "3  0.432121          1    -0.768909      0.253732       -0.592687  -0.764464   \n",
       "4  0.432201          1     1.750297     -1.151816        1.776573   1.826229   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0         1.568466          3.283515        2.652874             2.532475   \n",
       "1        -0.826962         -0.487072       -0.023846             0.548144   \n",
       "2         0.942210          1.052926        1.363478             2.037231   \n",
       "3         3.283553          3.402909        1.915897             1.451707   \n",
       "4         0.280372          0.539340        1.371011             1.428493   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...      1.886690      -1.359293         2.303601    2.001237   \n",
       "1  ...      1.805927      -0.369203         1.535126    1.890489   \n",
       "2  ...      1.511870      -0.023974         1.347475    1.456285   \n",
       "3  ...     -0.281464       0.133984        -0.249939   -0.550021   \n",
       "4  ...      1.298575      -1.466770         1.338539    1.220724   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0          1.307686           2.616665         2.109526              2.296076   \n",
       "1         -0.375612          -0.430444        -0.146749              1.087084   \n",
       "2          0.527407           1.082932         0.854974              1.955000   \n",
       "3          3.394275           3.893397         1.989588              2.175786   \n",
       "4          0.220556          -0.313395         0.613179              0.729259   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0        2.750622                 1.937015  \n",
       "1       -0.243890                 0.281190  \n",
       "2        1.152255                 0.201391  \n",
       "3        6.046041                 4.935010  \n",
       "4       -0.868353                -0.397100  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_scaled = feature_scaling(df_na_val,'diagnosis')\n",
    "cleaned_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c4f63ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>2.217515</td>\n",
       "      <td>...</td>\n",
       "      <td>1.886690</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>...</td>\n",
       "      <td>1.805927</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>0.939685</td>\n",
       "      <td>...</td>\n",
       "      <td>1.511870</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>2.867383</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281464</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>-0.009560</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298575</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1     1.097064     -2.073335        1.269934   0.984375   \n",
       "1          1     1.829821     -0.353632        1.685955   1.908708   \n",
       "2          1     1.579888      0.456187        1.566503   1.558884   \n",
       "3          1    -0.768909      0.253732       -0.592687  -0.764464   \n",
       "4          1     1.750297     -1.151816        1.776573   1.826229   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0         1.568466          3.283515        2.652874             2.532475   \n",
       "1        -0.826962         -0.487072       -0.023846             0.548144   \n",
       "2         0.942210          1.052926        1.363478             2.037231   \n",
       "3         3.283553          3.402909        1.915897             1.451707   \n",
       "4         0.280372          0.539340        1.371011             1.428493   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0       2.217515  ...      1.886690      -1.359293         2.303601   \n",
       "1       0.001392  ...      1.805927      -0.369203         1.535126   \n",
       "2       0.939685  ...      1.511870      -0.023974         1.347475   \n",
       "3       2.867383  ...     -0.281464       0.133984        -0.249939   \n",
       "4      -0.009560  ...      1.298575      -1.466770         1.338539   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0    2.001237          1.307686           2.616665         2.109526   \n",
       "1    1.890489         -0.375612          -0.430444        -0.146749   \n",
       "2    1.456285          0.527407           1.082932         0.854974   \n",
       "3   -0.550021          3.394275           3.893397         1.989588   \n",
       "4    1.220724          0.220556          -0.313395         0.613179   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0              2.296076        2.750622                 1.937015  \n",
       "1              1.087084       -0.243890                 0.281190  \n",
       "2              1.955000        1.152255                 0.201391  \n",
       "3              2.175786        6.046041                 4.935010  \n",
       "4              0.729259       -0.868353                -0.397100  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data = cleaned_scaled.drop(['id'], axis = 1)\n",
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de91669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.to_csv('/home/amon/Desktop/10Academy/industry-casualty/Data/clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a344ddc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-26 10:20:16,495 - XgModeller initialized...\n"
     ]
    }
   ],
   "source": [
    "from xgboost_modeller import XgModeller\n",
    "mdlr = XgModeller()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "398dee93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-26 10:20:21,548 - Randomized+SearchCV in process, 'n_estimators'=15 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:20:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.07, max_depth=5, min_child_weight=1.5, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.6; total time=   0.6s\n",
      "[10:20:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.07, max_depth=5, min_child_weight=1.5, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.6; total time=   0.1s\n",
      "[10:20:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.07, max_depth=5, min_child_weight=1.5, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.6; total time=   0.0s\n",
      "[10:20:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.07, max_depth=5, min_child_weight=1.5, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.6; total time=   0.1s\n",
      "[10:20:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.07, max_depth=5, min_child_weight=1.5, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.6; total time=   0.1s\n",
      "[10:20:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1.5, n_estimators=20, reg_alpha=0.01, reg_lambda=1e-05, subsample=0.95; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:20:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1.5, n_estimators=20, reg_alpha=0.01, reg_lambda=1e-05, subsample=0.95; total time=   0.1s\n",
      "[10:20:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1.5, n_estimators=20, reg_alpha=0.01, reg_lambda=1e-05, subsample=0.95; total time=   0.1s\n",
      "[10:20:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1.5, n_estimators=20, reg_alpha=0.01, reg_lambda=1e-05, subsample=0.95; total time=   0.1s\n",
      "[10:20:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=1.5, n_estimators=20, reg_alpha=0.01, reg_lambda=1e-05, subsample=0.95; total time=   0.1s\n",
      "[10:20:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.07, max_depth=5, min_child_weight=10, n_estimators=20, reg_alpha=1e-05, reg_lambda=0.45, subsample=0.6; total time=   0.0s\n",
      "[10:20:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.07, max_depth=5, min_child_weight=10, n_estimators=20, reg_alpha=1e-05, reg_lambda=0.45, subsample=0.6; total time=   0.0s\n",
      "[10:20:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.07, max_depth=5, min_child_weight=10, n_estimators=20, reg_alpha=1e-05, reg_lambda=0.45, subsample=0.6; total time=   0.1s\n",
      "[10:20:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.07, max_depth=5, min_child_weight=10, n_estimators=20, reg_alpha=1e-05, reg_lambda=0.45, subsample=0.6; total time=   0.0s\n",
      "[10:20:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.07, max_depth=5, min_child_weight=10, n_estimators=20, reg_alpha=1e-05, reg_lambda=0.45, subsample=0.6; total time=   0.0s\n",
      "[10:20:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.07, max_depth=5, min_child_weight=1.5, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.6; total time=   0.0s\n",
      "[10:20:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.07, max_depth=5, min_child_weight=1.5, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.6; total time=   0.1s\n",
      "[10:20:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.07, max_depth=5, min_child_weight=1.5, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.6; total time=   0.0s\n",
      "[10:20:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.07, max_depth=5, min_child_weight=1.5, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.6; total time=   0.0s\n",
      "[10:20:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.4, gamma=0.1, learning_rate=0.07, max_depth=5, min_child_weight=1.5, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.6; total time=   0.0s\n",
      "[10:20:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.6, gamma=0.03, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.95; total time=   0.0s\n",
      "[10:20:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.6, gamma=0.03, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.95; total time=   0.0s\n",
      "[10:20:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6, gamma=0.03, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.95; total time=   0.0s\n",
      "[10:20:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.6, gamma=0.03, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.95; total time=   0.0s\n",
      "[10:20:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.6, gamma=0.03, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.95; total time=   0.0s\n",
      "[10:20:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1.5, n_estimators=20, reg_alpha=0.75, reg_lambda=0.01, subsample=0.6; total time=   0.0s\n",
      "[10:20:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1.5, n_estimators=20, reg_alpha=0.75, reg_lambda=0.01, subsample=0.6; total time=   0.0s\n",
      "[10:20:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1.5, n_estimators=20, reg_alpha=0.75, reg_lambda=0.01, subsample=0.6; total time=   0.1s\n",
      "[10:20:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1.5, n_estimators=20, reg_alpha=0.75, reg_lambda=0.01, subsample=0.6; total time=   0.0s\n",
      "[10:20:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1.5, n_estimators=20, reg_alpha=0.75, reg_lambda=0.01, subsample=0.6; total time=   0.0s\n",
      "[10:20:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.6, gamma=0.03, learning_rate=0.1, max_depth=3, min_child_weight=1.5, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.6; total time=   0.0s\n",
      "[10:20:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.6, gamma=0.03, learning_rate=0.1, max_depth=3, min_child_weight=1.5, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.6; total time=   0.0s\n",
      "[10:20:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6, gamma=0.03, learning_rate=0.1, max_depth=3, min_child_weight=1.5, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.6; total time=   0.1s\n",
      "[10:20:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.6, gamma=0.03, learning_rate=0.1, max_depth=3, min_child_weight=1.5, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.6; total time=   0.0s\n",
      "[10:20:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.6, gamma=0.03, learning_rate=0.1, max_depth=3, min_child_weight=1.5, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.6; total time=   0.0s\n",
      "[10:20:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.95; total time=   0.0s\n",
      "[10:20:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.95; total time=   0.0s\n",
      "[10:20:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.95; total time=   0.0s\n",
      "[10:20:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.95; total time=   0.0s\n",
      "[10:20:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.6, gamma=0.3, learning_rate=0.1, max_depth=5, min_child_weight=6, n_estimators=20, reg_alpha=0.75, reg_lambda=0.45, subsample=0.95; total time=   0.0s\n",
      "[10:20:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.4, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1.5, n_estimators=20, reg_alpha=1e-05, reg_lambda=0.45, subsample=0.95; total time=   0.0s\n",
      "[10:20:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.4, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1.5, n_estimators=20, reg_alpha=1e-05, reg_lambda=0.45, subsample=0.95; total time=   0.0s\n",
      "[10:20:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.4, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1.5, n_estimators=20, reg_alpha=1e-05, reg_lambda=0.45, subsample=0.95; total time=   0.0s\n",
      "[10:20:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.4, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1.5, n_estimators=20, reg_alpha=1e-05, reg_lambda=0.45, subsample=0.95; total time=   0.0s\n",
      "[10:20:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.4, gamma=0, learning_rate=0.1, max_depth=3, min_child_weight=1.5, n_estimators=20, reg_alpha=1e-05, reg_lambda=0.45, subsample=0.95; total time=   0.0s\n",
      "[10:20:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.4, gamma=0.03, learning_rate=0.1, max_depth=3, min_child_weight=1.5, n_estimators=20, reg_alpha=1e-05, reg_lambda=0.45, subsample=0.6; total time=   0.0s\n",
      "[10:20:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.4, gamma=0.03, learning_rate=0.1, max_depth=3, min_child_weight=1.5, n_estimators=20, reg_alpha=1e-05, reg_lambda=0.45, subsample=0.6; total time=   0.0s\n",
      "[10:20:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.4, gamma=0.03, learning_rate=0.1, max_depth=3, min_child_weight=1.5, n_estimators=20, reg_alpha=1e-05, reg_lambda=0.45, subsample=0.6; total time=   0.0s\n",
      "[10:20:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.4, gamma=0.03, learning_rate=0.1, max_depth=3, min_child_weight=1.5, n_estimators=20, reg_alpha=1e-05, reg_lambda=0.45, subsample=0.6; total time=   0.0s\n",
      "[10:20:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.4, gamma=0.03, learning_rate=0.1, max_depth=3, min_child_weight=1.5, n_estimators=20, reg_alpha=1e-05, reg_lambda=0.45, subsample=0.6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amon/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "2021-08-26 10:20:25,354 - RandomizedSearchCV in completed\n",
      "2021-08-26 10:20:25,355 - Best_estimator in retrieved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:20:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "base, best = mdlr.gridsearch_model(X=x, Y=y, output=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4e93ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = best.get_xgb_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2a0a584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-26 10:21:41,379 - Feature importance plotting in process...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mdlr.best_feature_imp(max_feats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb8551c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = x[['texture_mean', 'radius_worst', 'texture_worst', 'concavity_worst', 'area_se']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1333572",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features['diagnosis']=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ffa970e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>area_se</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.77</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>74.08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.25</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>94.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.34</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>94.44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.70</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>27.19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.98</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>53.91</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   texture_mean  radius_worst  texture_worst  concavity_worst  area_se  \\\n",
       "1         17.77         24.99          23.41           0.2416    74.08   \n",
       "2         21.25         23.57          25.53           0.4504    94.03   \n",
       "4         14.34         22.54          16.67           0.4000    94.44   \n",
       "5         15.70         15.47          23.75           0.5355    27.19   \n",
       "6         19.98         22.88          27.66           0.3784    53.91   \n",
       "\n",
       "   diagnosis  \n",
       "1          1  \n",
       "2          1  \n",
       "4          1  \n",
       "5          1  \n",
       "6          1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d9459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
